{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dGtRFIXgRWAN"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class Patterns:\n",
    "    URL_PATTERN=re.compile(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?\\xab\\xbb\\u201c\\u201d\\u2018\\u2019]))')\n",
    "    HASHTAG_PATTERN = re.compile(r'(?P<hashtag>#\\w*)')\n",
    "    MENTION_PATTERN = re.compile(r'@\\w*')\n",
    "    RESERVED_WORDS_PATTERN = re.compile(r'^(RT|FAV)') # tweeter reserved words\n",
    "\n",
    "    try:\n",
    "        # UCS-4\n",
    "        EMOJIS_PATTERN = re.compile(u'([\\U00002600-\\U000027BF])|([\\U0001f300-\\U0001f64F])|([\\U0001f680-\\U0001f6FF])')\n",
    "    except re.error:\n",
    "        # UCS-2\n",
    "        EMOJIS_PATTERN = re.compile(u'([\\u2600-\\u27BF])|([\\uD83C][\\uDF00-\\uDFFF])|([\\uD83D][\\uDC00-\\uDE4F])|([\\uD83D][\\uDE80-\\uDEFF])')\n",
    "\n",
    "    SMILEYS_PATTERN = re.compile(r\"(?:X|:|;|=)(?:-)?(?:\\)|\\(|O|D|P|S){1,}\", re.IGNORECASE)\n",
    "    NUMBERS_PATTERN = re.compile(r\"(^|\\s)(\\-?\\d+(?:\\.\\d)*|\\d+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PsGJONMcRjBw"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import datetime\n",
    "from tweepy import Cursor\n",
    "\n",
    "consumer_key = \"RJu751Asy2vHaUaFSLGtGxWhx\"\n",
    "consumer_secret = \"wvf4GLYEzP1Die5MRKd6DK1d0FCWiJKnMLJP1aQ7H28QBfIDRm\" \n",
    "access_token = \"1314603303796383746-hLWMOuVjFen5LOPQ7R600uJ6c38alm\"\n",
    "access_token_secret = \"ZiLQteu4MuHxkKCjhaF0Oqt1znwDrkI37AdONbODVtFe8\"\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TyU5RiHtRkTF"
   },
   "outputs": [],
   "source": [
    "def clean_tweets(rawData):\n",
    "  cleanData = []\n",
    "  for obj in rawData:\n",
    "    obj = re.sub(Patterns.URL_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.HASHTAG_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.MENTION_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.RESERVED_WORDS_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.EMOJIS_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.EMOJIS_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.SMILEYS_PATTERN, \"\", obj)\n",
    "    obj = re.sub(Patterns.NUMBERS_PATTERN , \"\", obj)\n",
    "    obj = obj.rstrip(\"\\n\")\n",
    "    obj = obj.replace(\"\\n\",\"\")\n",
    "    cleanData.append(obj)\n",
    "  return cleanData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "O3pjSv6-UyVv"
   },
   "outputs": [],
   "source": [
    "def extract_tweets(query):\n",
    "    tweets=[]\n",
    "    for status in Cursor(api.search,lang=\"en\",\n",
    "                     q=query, tweet_mode = 'extended', retweet_mode = 'extended', truncated=False).items(2500):\n",
    "        tweets.append(status)\n",
    "    return tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "EBPWE17AU1Nn"
   },
   "outputs": [],
   "source": [
    "search_keywords = \"Storm OR Winter OR Canada OR Temperature OR Flu OR Snow OR Indoor OR Safety\"\n",
    "tweets = extract_tweets(search_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oDmFxDMYU3h7",
    "outputId": "30fe7d70-4c9a-4092-db79-810db7965e01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @tammyingram: And I posted this the other day, but while I was away on a fellowship, there was a hurricane in Charleston, so my moto boy…\n"
     ]
    }
   ],
   "source": [
    "rawTweets=[]\n",
    "print(tweets[0].full_text)\n",
    "for tweet in tweets:\n",
    "    rawTweets.append(tweet.full_text) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "8bfdGiI7ViuF",
    "outputId": "cdc299a8-9c7b-4aa5-acdf-ae05827c5e58"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' : And I posted this the other day, but while I was away on a fellowship, there was a hurricane in Charleston, so my moto boy…'"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanTweets = clean_tweets(rawTweets)\n",
    "cleanTweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FA5iMwT-U6P5",
    "outputId": "35ee0939-3cf4-4aca-b9e2-1fde873181ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "uExk8PuMU-jH"
   },
   "outputs": [],
   "source": [
    "bagOfWordsList = []\n",
    "for tweet in cleanTweets:\n",
    "    bagOfWords = {}\n",
    "    words = word_tokenize(tweet)\n",
    "    for word in words:\n",
    "        if word in bagOfWords:\n",
    "            bagOfWords[word] +=1\n",
    "        else:\n",
    "            bagOfWords[word] =1\n",
    "    bagOfWordsList.append(bagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "DKrqIrdBb_Aa"
   },
   "outputs": [],
   "source": [
    "positive_words = []\n",
    "positiveFile = open(\"positive-words.txt\",\"r\")\n",
    "words = positiveFile.readlines()\n",
    "for word in words:\n",
    "  word = word.rstrip(\"\\n\")\n",
    "  positive_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Vhz_LueTeKnH"
   },
   "outputs": [],
   "source": [
    "negative_words = []\n",
    "negativeFile = open(\"negative-words.txt\",\"r\")\n",
    "words = negativeFile.readlines()\n",
    "for word in words:\n",
    "  word = word.rstrip(\"\\n\")\n",
    "  negative_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Ewx02hereZNH"
   },
   "outputs": [],
   "source": [
    "finalData = []\n",
    "i = 0\n",
    "while( i < len(bagOfWordsList) ):\n",
    "    bagOfWords = bagOfWordsList[i]\n",
    "    row = {\n",
    "        \"Tweet\": i+1,\n",
    "        \"Message\": cleanTweets[i],\n",
    "        \"Matches\": [],\n",
    "        \"Polarity\": \"\"\n",
    "    }\n",
    "    posCount = 0\n",
    "    negCount = 0\n",
    "    posMatch = []\n",
    "    negMatch = []\n",
    "    for word, count in bagOfWords.items():\n",
    "      if word in positive_words:\n",
    "        posCount += 1*count\n",
    "        posMatch.append(word)\n",
    "      if word in negative_words:\n",
    "        negCount += 1*count\n",
    "        negMatch.append(word)\n",
    "    res = posCount - negCount\n",
    "    if (res > 0):\n",
    "      row[\"Polarity\"] = \"Positive\"\n",
    "      row[\"Matches\"] = posMatch\n",
    "    elif (res < 0):\n",
    "      row[\"Polarity\"] = \"Negative\"\n",
    "      row[\"Matches\"] = negMatch\n",
    "    elif (res == 0):\n",
    "      row[\"Polarity\"] = \"Neutral\"\n",
    "      row[\"Matches\"] = []\n",
    "    finalData.append(row)\n",
    "    i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Gixpxu8hjFrv"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweet_analysis = pd.DataFrame(finalData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "ykODdcEIjP-P",
    "outputId": "a92b6c8a-b035-4494-9bea-d1a1aad86b06"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Message</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>: And I posted this the other day, but while ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>I'm in Canada. I had to see the trailer the ...</td>\n",
       "      <td>[fans]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>: Boyz II Men &amp;amp; Brian McKnight - Let It S...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Tbf I find it jokes how only,000 Millwall on t...</td>\n",
       "      <td>[rattle, flake]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Nope snow really bad like a snowicane!. Uz okie?</td>\n",
       "      <td>[]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2495</th>\n",
       "      <td>2496</td>\n",
       "      <td>: when your breath does the Thing in winter a...</td>\n",
       "      <td>[pretend]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2496</th>\n",
       "      <td>2497</td>\n",
       "      <td>Fellow New Englanders today, wishing you the b...</td>\n",
       "      <td>[best, luck]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>2498</td>\n",
       "      <td>: There's just a lot of liquid with this stor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>2499</td>\n",
       "      <td>I've never technically left America, although ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>2500</td>\n",
       "      <td>Sir you’re forewarned. We’re on the hunt for ...</td>\n",
       "      <td>[well]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2500 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Tweet  ...  Polarity\n",
       "0         1  ...   Neutral\n",
       "1         2  ...  Positive\n",
       "2         3  ...   Neutral\n",
       "3         4  ...  Negative\n",
       "4         5  ...   Neutral\n",
       "...     ...  ...       ...\n",
       "2495   2496  ...  Negative\n",
       "2496   2497  ...  Positive\n",
       "2497   2498  ...   Neutral\n",
       "2498   2499  ...   Neutral\n",
       "2499   2500  ...  Positive\n",
       "\n",
       "[2500 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "KDo3SAVmms71"
   },
   "outputs": [],
   "source": [
    "tweet_analysis.to_csv(\"tweet_analysis.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "A4_sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
